{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.ao.quantization as quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2469e1a8e30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MNIST...\n",
    "# mean value = 0.0.1307\n",
    "# var = 0.3081\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='data/', train = True, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='data/', train = False, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size = 64, shuffle = True)\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "The architecture of model and the training and testing processes are same, only few modification to show the training result.\n",
    "\n",
    "* `fuse_model`: Fuse two layers together, since qint8 cannot be dealt with normal arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, neuron_1 = 64, neuron_2 = 64):\n",
    "        super().__init__()\n",
    "        self.quant = quant.QuantStub()\n",
    "        self.linear1 = nn.Linear(28 * 28, neuron_1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(neuron_1, neuron_2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(neuron_2, 10)\n",
    "        self.dequant = quant.DeQuantStub()\n",
    "        \n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.reshape(-1, 28 * 28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "    \n",
    "    def fuse_model(self):\n",
    "        torch.ao.quantization.fuse_modules(self, [['linear1', 'relu1'], ['linear2', 'relu2']], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "* `print_size_of_model`: Calculate the size of model\n",
    "    1. Save the model\n",
    "    2. `os.path.getsize`\n",
    "    3. Remove the saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [00:20<00:00, 46.54it/s, loss=tensor(0.3070, grad_fn=<DivBackward0>)]\n",
      "Epoch 2: 100%|██████████| 938/938 [00:20<00:00, 45.28it/s, loss=tensor(0.1362, grad_fn=<DivBackward0>)]\n",
      "Epoch 3: 100%|██████████| 938/938 [00:20<00:00, 46.24it/s, loss=tensor(0.0981, grad_fn=<DivBackward0>)]\n",
      "Epoch 4: 100%|██████████| 938/938 [00:20<00:00, 45.74it/s, loss=tensor(0.0758, grad_fn=<DivBackward0>)]\n",
      "Epoch 5: 100%|██████████| 938/938 [00:20<00:00, 45.65it/s, loss=tensor(0.0629, grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs = 5, total_iterations_limit = None):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc = f'Epoch {epoch + 1}') # shows the training process\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        \n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            output = net(x)\n",
    "            loss = loss_fn(output, y)\n",
    "            loss_sum += loss\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss) # post_fix for tqdm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "    \n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), 'temp_delme.p')\n",
    "    print('Size (KB):', os.path.getsize('temp_delme.p') / 1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'simplenet_ptq.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(train_loader, net, epochs=5)\n",
    "    # Save the model to disk\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, total_iterations=None):\n",
    "    model.eval()\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterations = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(\"cpu\")\n",
    "            y = y.to(\"cpu\")\n",
    "\n",
    "            output = model(x)\n",
    "\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            iterations += 1\n",
    "\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "\n",
    "    print(f'Accuracy: {round(correct / total, 3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights and size of the model before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[ 0.0128, -0.0026, -0.0295,  ..., -0.0194,  0.0109, -0.0084],\n",
      "        [ 0.0464,  0.0048,  0.0133,  ...,  0.0520,  0.0025, -0.0120],\n",
      "        [ 0.0395,  0.0317, -0.0237,  ..., -0.0278, -0.0207,  0.0277],\n",
      "        ...,\n",
      "        [ 0.0363,  0.0409,  0.0370,  ...,  0.0066,  0.0480,  0.0488],\n",
      "        [-0.0257, -0.0119,  0.0268,  ...,  0.0260, -0.0261, -0.0349],\n",
      "        [ 0.0340,  0.0216,  0.0462,  ...,  0.0387,  0.0491,  0.0531]],\n",
      "       requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print('Weights before quantization')\n",
    "print(net.linear1.weight)\n",
    "print(net.linear1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB): 222.886\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model before quantization')\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:02<00:00, 71.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the model before quantization: ')\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "print(type(net.linear1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `get_default_qconfig`: Call API to start quantization. Define the configuration as \"fbgemm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n"
     ]
    }
   ],
   "source": [
    "import torch.ao.quantization\n",
    "\n",
    "net.fuse_model()\n",
    "net.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
    "print(net.qconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `prepare`: Insert the observers for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization Prepare: Inserting Observers\n",
      "\n",
      " Inverted Residual Block:After observer insertion \n",
      "\n",
      " LinearReLU(\n",
      "  (0): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorden\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.ao.quantization.prepare(net, inplace = True)\n",
    "# Calibrate first\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Inverted Residual Block:After observer insertion \\n\\n', net.linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calibration: Training (testing) the model for one epoch to get the parameters in obervers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:02<00:00, 62.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971\n",
      "Post Training Quantization: Calibration done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(net)\n",
    "print('Post Training Quantization: Calibration done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `convert`: Convert the model into quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization: Convert done\n",
      "\n",
      " Inverted Residual Block: After fusion and quantization, note fused modules: \n",
      "\n",
      " QuantizedLinearReLU(in_features=784, out_features=64, scale=0.22460556030273438, zero_point=0, qscheme=torch.per_channel_affine)\n"
     ]
    }
   ],
   "source": [
    "torch.ao.quantization.convert(net, inplace = True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Inverted Residual Block: After fusion and quantization, note fused modules: \\n\\n',net.linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of model after quantization\n",
      "Size (KB): 64.354\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:02<00:00, 73.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is successfully quantized, the name of the layer will start with `quantized...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (quant): Quantize(scale=tensor([0.0255]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (linear1): QuantizedLinearReLU(in_features=784, out_features=64, scale=0.22460556030273438, zero_point=0, qscheme=torch.per_channel_affine)\n",
      "  (relu1): Identity()\n",
      "  (linear2): QuantizedLinearReLU(in_features=64, out_features=64, scale=0.1565181165933609, zero_point=0, qscheme=torch.per_channel_affine)\n",
      "  (relu2): Identity()\n",
      "  (linear3): QuantizedLinear(in_features=64, out_features=10, scale=0.44150465726852417, zero_point=76, qscheme=torch.per_channel_affine)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **scale**: The step size between quantized levels.\n",
    "* **zero_point**: The integer value in the quantized range that maps to real zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0131, -0.0022, -0.0305,  ..., -0.0196,  0.0109, -0.0087],\n",
      "        [ 0.0472,  0.0054,  0.0127,  ...,  0.0526,  0.0018, -0.0127],\n",
      "        [ 0.0386,  0.0331, -0.0248,  ..., -0.0276, -0.0220,  0.0276],\n",
      "        ...,\n",
      "        [ 0.0358,  0.0409,  0.0358,  ...,  0.0077,  0.0486,  0.0486],\n",
      "        [-0.0252, -0.0126,  0.0270,  ...,  0.0252, -0.0252, -0.0342],\n",
      "        [ 0.0350,  0.0225,  0.0450,  ...,  0.0375,  0.0501,  0.0526]])\n",
      "----------------------------------------------------------------------------\n",
      "0.22460556030273438\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.dequantize(net.linear1.weight()))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(net.linear1.scale)\n",
    "print(net.linear1.zero_point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model.linear1.weight().int_repr()`: Accessing the quantized tensor; use .int_repr() to retrieve its underlying int8 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6,  -1, -14,  ...,  -9,   5,  -4],\n",
      "        [ 26,   3,   7,  ...,  29,   1,  -7],\n",
      "        [ 14,  12,  -9,  ..., -10,  -8,  10],\n",
      "        ...,\n",
      "        [ 14,  16,  14,  ...,   3,  19,  19],\n",
      "        [-14,  -7,  15,  ...,  14, -14, -19],\n",
      "        [ 14,   9,  18,  ...,  15,  20,  21]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "weight_q = net.linear1.weight()\n",
    "weight_int8 = weight_q.int_repr()\n",
    "print(weight_int8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
