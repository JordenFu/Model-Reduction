{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6ecde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch.ao.quantization as quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560f1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "['none', 'onednn', 'x86', 'fbgemm']\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "torch.backends.quantized.engine = 'fbgemm'\n",
    "print(torch.backends.quantized.supported_engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fa67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "mnist_trainset = MNIST(root = 'data/', train = True, transform = transform)\n",
    "mnist_testset = MNIST(root = 'data/', train = False, transform = transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_trainset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28865aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5890685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.ao.quantization\n",
    "\n",
    "\n",
    "class TrainingMNISTModel(nn.Module):\n",
    "    def __init__(self, neuron_1 = 64, neuron_2 = 64):\n",
    "        super(TrainingMNISTModel, self).__init__()\n",
    "        self.quant = quant.QuantStub()\n",
    "        self.linear1 = nn.Linear(28 * 28, neuron_1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(neuron_1, neuron_2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(neuron_2, 10)\n",
    "        self.dequant = quant.DeQuantStub()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.reshape(-1, 28 * 28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "    \n",
    "    def fuse_model(self):\n",
    "        # Fuse layers for quantization\n",
    "        torch.ao.quantization.fuse_modules(self, [['linear1', 'relu1'], ['linear2', 'relu2']], inplace = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160cbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model = TrainingMNISTModel().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(qat_model.parameters(), lr = learning_rate, weight_decay= 1e-4) # L2-regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257c3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epochs = 5, total_iterations_limit = None):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        \n",
    "        data_iterator = tqdm(train_loader, desc = f'Epoch {epoch + 1}') # desc = description\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "            loss = loss_fn(output, y)\n",
    "            loss_sum += loss\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss = avg_loss) # post_fix for tqdm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "            \n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), 'temp_delme.p')\n",
    "    print('Size (KB)', os.path.getsize('temp_delme.p') / 1e3)\n",
    "    os.remove('temp_delme.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5df233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILENAME = 'mnistmodel_qat.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    qat_model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(train_loader, qat_model, epochs = 5)\n",
    "    # Save the model to disk\n",
    "    torch.save(qat_model.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa57c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, total_iterations = None):\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterations = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for data in tqdm(test_loader, desc = 'Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            iterations += 1\n",
    "\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "\n",
    "    print(f'Accuracy: {round(correct / total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71287721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before QAT\n",
      "Parameter containing:\n",
      "tensor([[ 0.0394,  0.0418,  0.0037,  ..., -0.0020,  0.0214,  0.0256],\n",
      "        [-0.0038, -0.0204,  0.0337,  ...,  0.0044,  0.0149,  0.0265],\n",
      "        [ 0.0006,  0.0030,  0.0059,  ..., -0.0113, -0.0175,  0.0072],\n",
      "        ...,\n",
      "        [-0.0320, -0.0422, -0.0065,  ...,  0.0089, -0.0336,  0.0155],\n",
      "        [ 0.0100, -0.0117,  0.0249,  ...,  0.0118,  0.0005, -0.0186],\n",
      "        [ 0.0407, -0.0163,  0.0370,  ...,  0.0396,  0.0056,  0.0238]],\n",
      "       requires_grad=True)\n",
      "torch.float32\n",
      "Size of the model before QAT\n",
      "Size (KB) 222.886\n",
      "Accuracy of the model before QAT: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 313/313 [00:02<00:00, 138.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print('Weights before QAT')\n",
    "print(qat_model.linear1.weight)\n",
    "print(qat_model.linear1.weight.dtype)\n",
    "\n",
    "print('Size of the model before QAT')\n",
    "print_size_of_model(qat_model)\n",
    "\n",
    "print(f'Accuracy of the model before QAT: ')\n",
    "test(qat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6006287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "print(type(qat_model.linear1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd800d",
   "metadata": {},
   "source": [
    "### Finished Pretrain, Start Quantization\n",
    "Start to do the quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b3d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize'>, observer=<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n"
     ]
    }
   ],
   "source": [
    "qat_model.train()\n",
    "qat_model.fuse_model()\n",
    "qat_model.qconfig = quant.get_default_qat_qconfig('fbgemm')\n",
    "print(qat_model.qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d83aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorden\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning the model with QAT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1875 [00:00<?, ?it/s, loss=tensor(0.0041, grad_fn=<DivBackward0>)]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1875/1875 [00:25<00:00, 72.65it/s, loss=tensor(0.0564, grad_fn=<DivBackward0>)]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:25<00:00, 72.25it/s, loss=tensor(0.0476, grad_fn=<DivBackward0>)]\n",
      "Epoch 3: 100%|██████████| 1875/1875 [00:26<00:00, 71.09it/s, loss=tensor(0.0423, grad_fn=<DivBackward0>)]\n",
      "Epoch 4: 100%|██████████| 1875/1875 [00:30<00:00, 61.85it/s, loss=tensor(0.0374, grad_fn=<DivBackward0>)]\n",
      "Epoch 5: 100%|██████████| 1875/1875 [00:35<00:00, 52.83it/s, loss=tensor(0.0352, grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# prepare QAT\n",
    "torch.quantization.prepare_qat(qat_model, inplace = True)\n",
    "\n",
    "# Fine-tune the model with QAT\n",
    "print(\"Fine-tuning the model with QAT...\")\n",
    "train(train_loader, qat_model, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e6ce472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted to quantized version.\n",
      "\n",
      " Inverted Residual Block: After fusion and QAT, note fused modules: \n",
      "\n",
      " QuantizedLinearReLU(in_features=784, out_features=64, scale=0.25556251406669617, zero_point=0, qscheme=torch.per_channel_affine)\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to a quantized version\n",
    "qat_model.eval()  # Switch to evaluation mode before conversion\n",
    "quant.convert(qat_model, inplace = True)\n",
    "print(\"Model converted to quantized version.\")\n",
    "\n",
    "print('\\n Inverted Residual Block: After fusion and QAT, note fused modules: \\n\\n',qat_model.linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12bb789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of model after QAT\n",
      "Size (KB) 64.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 313/313 [00:02<00:00, 136.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of model after QAT\")\n",
    "print_size_of_model(qat_model)\n",
    "\n",
    "test(qat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9713c755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0527,  0.0527,  0.0158,  ...,  0.0105,  0.0316,  0.0369],\n",
      "        [-0.0036, -0.0202,  0.0337,  ...,  0.0047,  0.0150,  0.0265],\n",
      "        [ 0.0174,  0.0174,  0.0209,  ...,  0.0035, -0.0035,  0.0244],\n",
      "        ...,\n",
      "        [-0.0411, -0.0513, -0.0154,  ...,  0.0000, -0.0462,  0.0051],\n",
      "        [ 0.0175, -0.0035,  0.0350,  ...,  0.0210,  0.0105, -0.0105],\n",
      "        [ 0.0434, -0.0109,  0.0434,  ...,  0.0434,  0.0109,  0.0271]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.dequantize(qat_model.linear1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4320c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "0.25556251406669617\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(qat_model.linear1.scale)\n",
    "print(qat_model.linear1.zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c584973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10,  10,   3,  ...,   2,   6,   7],\n",
      "        [ -7, -39,  65,  ...,   9,  29,  51],\n",
      "        [  5,   5,   6,  ...,   1,  -1,   7],\n",
      "        ...,\n",
      "        [ -8, -10,  -3,  ...,   0,  -9,   1],\n",
      "        [  5,  -1,  10,  ...,   6,   3,  -3],\n",
      "        [  8,  -2,   8,  ...,   8,   2,   5]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "weight_q = qat_model.linear1.weight()\n",
    "weight_int8 = weight_q.int_repr()\n",
    "print(weight_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71170541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69cbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
